# Copyright 2022 OmniSafe Team. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

defaults:
  # Basic Configurations
  max_real_time_steps: 1000000
  max_ep_len: 1000
  action_repeat: 5
  seed: 0
  device: "cuda:0"
  cost_gamma: 1.0

  # Soft Actor-Critic
  update_policy_start_timesteps: 50000
  update_policy_freq: 250
  update_policy_iters: 50
  ac_hidden_sizes: [64, 64]
  sac_lr: 0.001
  alpha_init: 0.2
  automatic_alpha_tuning: True
  gamma: 0.99
  polyak: 0.995
  use_bc_loss: False
  sac_config_evaluation_mode: None

  # log
  log_freq: 20000
  data_dir: "./runs"

  # Optional Configuration
  use_cost_critic: False
  reward_penalty: False
  scale_rewards: False
  standardized_obs: False
  exploration_noise: 0.0


  # Configuration For Off-policy Buffer
  replay_size: 1000000
  batch_size: 256

  # Configuration For dynamics model
  update_dynamics_freq: 1250
  dynamics_cfgs:
    network_size: 7
    elite_size: 5
    hidden_size: 200
    use_decay: True

  # Configuration For MPC controller
  mpc_config:
    horizon: 8
    reward_horizon: 8
    popsize: 100
    particles: 4
    max_iters: 8
    alpha: 0.1
    mixture_coefficient: 0.05
    kappa: 1
    safety_threshold: 0.2
    minimal_elites: 10
    num_elites: 20
